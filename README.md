# Supervised Learning Plan

Supervised learning is a type of machine learning where models are trained using labeled data. The model learns the relationship between input features and output labels to make predictions on unseen data. Supervised learning is mainly divided into **Classification** and **Regression**.

---

## 1. Classification Algorithms

Classification is used to predict **categorical outcomes**. The following algorithms are covered:

1. **Logistic Regression**  
   - Predicts probabilities for categorical classes using a logistic function.  
   - Commonly used for binary classification problems.

2. **Decision Tree**  
   - Uses a tree-like structure to split data based on feature values.  
   - Simple to understand and interpret.

3. **Random Forest**  
   - An ensemble method that combines multiple decision trees.  
   - Improves accuracy and reduces overfitting.

4. **Support Vector Machine (SVM)**  
   - Finds the optimal hyperplane that separates classes in the feature space.  
   - Supports linear and nonlinear classification using kernels.

5. **K-Nearest Neighbors (KNN)**  
   - Classifies a data point based on the majority class of its nearest neighbors.  
   - Instance-based and non-parametric algorithm.

6. **Gradient Boosting**  
   - An ensemble learning technique that builds models sequentially.  
   - Each new model focuses on correcting the errors of previous models.  
   - Common implementations include Gradient Boosting Classifier, XGBoost, and LightGBM.

 

---

## 2. Regression Algorithms

Regression is used to predict **continuous numerical values**. The following algorithms are covered:

1. **Linear Regression**  
   - Models the linear relationship between input features and a continuous output.

2. **Polynomial Regression**  
   - Extends linear regression to capture nonlinear relationships using polynomial terms.

3. **Multiple Regression**  
   - Uses multiple input variables to predict a single continuous output.

4. **Ridge Regression**  
   - Linear regression with L2 regularization to reduce overfitting.

5. **Lasso Regression**  
   - Linear regression with L1 regularization that can also perform feature selection.

6. **Elastic Net Regression**  
   - Combines L1 and L2 regularization techniques.

---

This supervised learning plan outlines the key algorithms used for both classification and regression, providing a structured approach to understanding predictive modeling techniques.
